{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93579217",
   "metadata": {},
   "source": [
    "# Analyze an EMCEE run\n",
    "this will be command, bear with this notebook for now\n",
    "\n",
    "## 1. Create the gempyor object\n",
    "\n",
    "Just edit your config file and the path to the data repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c74234-90f5-463e-a685-ff9cf7620953",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T10:04:39.274921Z",
     "start_time": "2023-11-20T10:04:37.320752Z"
    },
    "execution": {
     "iopub.execute_input": "2023-05-04T14:52:29.916947Z",
     "iopub.status.busy": "2023-05-04T14:52:29.916341Z",
     "iopub.status.idle": "2023-05-04T14:52:37.018295Z",
     "shell.execute_reply": "2023-05-04T14:52:37.017535Z",
     "shell.execute_reply.started": "2023-05-04T14:52:29.916917Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 12 CPUs, using these\n",
      "  gempyor >> Running ***DETERMINISTIC*** simulation;\n",
      "  gempyor >> ModelInfo USA_inference_all; index: 1; run_id: SMH_Rdisparity_phase_one_phase1_blk1_fixprojnpis_CA-NC_emcee,\n",
      "  gempyor >> prefix: USA_inference_all/SMH_Rdisparity_phase_one_phase1_blk1_fixprojnpis_CA-NC_emcee/;\n",
      "Loaded subpops in loaded relative probablity file: 51 Intersect with seir simulation:  2 kept\n",
      "Running Gempyor Inference\n",
      "LogLoss: 6 statistics and 92 data points,number of NA for each statistic: \n",
      "incidD_latino    46\n",
      "incidD_other      0\n",
      "incidD_asian      0\n",
      "incidD_black      0\n",
      "incidD_white      0\n",
      "incidC_white     24\n",
      "incidC_black     24\n",
      "incidC_other     24\n",
      "incidC_asian     24\n",
      "incidC_latino    61\n",
      "incidC           24\n",
      "incidD            0\n",
      "dtype: int64\n",
      "InferenceParameters: with 92 parameters: \n",
      "    seir_modifiers: 84 parameters\n",
      "    outcome_modifiers: 8 parameters\n",
      "\n",
      "LogLoss: 6 statistics and 92 data points,number of NA for each statistic: \n",
      "incidD_latino    46\n",
      "incidD_other      0\n",
      "incidD_asian      0\n",
      "incidD_black      0\n",
      "incidD_white      0\n",
      "incidC_white     24\n",
      "incidC_black     24\n",
      "incidC_other     24\n",
      "incidC_asian     24\n",
      "incidC_latino    61\n",
      "incidC           24\n",
      "incidD            0\n",
      "dtype: int64\n",
      "InferenceParameters: with 92 parameters: \n",
      "    seir_modifiers: 84 parameters\n",
      "    outcome_modifiers: 8 parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gempyor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from gempyor import config\n",
    "from gempyor.inference import GempyorInference\n",
    "import gempyor.postprocess_inference\n",
    "import multiprocessing, shutil\n",
    "\n",
    "import os\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# disable  operations using the MKL linear algebra.\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import emcee\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "# Fill your config and the path to the data repository here \n",
    "project_path = \"../../COVID19_Disparities\"\n",
    "config_filepath = \"config_SMH_Rdisparity_phase_one_phase1_blk1_fixprojnpis_CA-NC_emcee.yml\"\n",
    "\n",
    "run_id = config_filepath.split(\"/\")[-1].split(\".\")[0].replace(\"config_\", \"\")\n",
    "\n",
    "#### START COPY PAST FROM flepiMoP/flepimop/gempyor_pkg/src/gempyor/calibrate.py\n",
    "ncpu = cpu_count()\n",
    "print(f\"found {ncpu} CPUs, using these\")\n",
    "\n",
    "gempyor_inference = GempyorInference(\n",
    "        config_filepath=config_filepath,\n",
    "        run_id=run_id,\n",
    "        prefix=None,\n",
    "        first_sim_index=1,\n",
    "        stoch_traj_flag=False,\n",
    "        rng_seed=None,\n",
    "        nslots=1,\n",
    "        inference_filename_prefix=\"global/final/\",  # usually for {global or chimeric}/{intermediate or final}\n",
    "        inference_filepath_suffix=\"\",  # usually for the slot_id\n",
    "        out_run_id=None,  # if out_run_id is different from in_run_id, fill this\n",
    "        out_prefix=None,  # if out_prefix is different from in_prefix, fill this\n",
    "        path_prefix=project_path,  # in case the data folder is on another directory\n",
    "        autowrite_seir=False,\n",
    ")\n",
    "nsubpop = len(gempyor_inference.modinf.subpop_struct.subpop_names)\n",
    "subpop_names = gempyor_inference.modinf.subpop_struct.subpop_names\n",
    "\n",
    "print(gempyor_inference.logloss)\n",
    "print(gempyor_inference.inferpar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed334f",
   "metadata": {},
   "source": [
    "## 2. Choose how many simulations you want to compute, and load the h5 file\n",
    "here change the filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f5cad0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d2b884",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "You must run the sampler with 'store == True' before accessing the results",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m chain_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# -1 for last\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# This selects the n_samples slots/walkers with the highest likelihood, and take their last evaluation. \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Debatable, but it's a start.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m max_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(sampler\u001b[38;5;241m.\u001b[39mget_log_prob()[chain_index, :])[\u001b[38;5;241m-\u001b[39mnsamples:]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(sampler\u001b[38;5;241m.\u001b[39mget_chain()\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m chains \u001b[38;5;241m=\u001b[39m sampler\u001b[38;5;241m.\u001b[39mget_chain()[:chain_index, max_indices, :]        \u001b[38;5;66;03m# the last iteration, for selected slots\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/emcee/backends/backend.py:109\u001b[0m, in \u001b[0;36mBackend.get_log_prob\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the chain of log probabilities evaluated at the MCMC samples\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_value(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/emcee/backends/hdf.py:152\u001b[0m, in \u001b[0;36mHDFBackend.get_value\u001b[0;34m(self, name, flat, thin, discard)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, flat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, thin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, discard\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized:\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must run the sampler with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore == True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m before accessing the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         )\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen() \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    158\u001b[0m         g \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname]\n",
      "\u001b[0;31mAttributeError\u001b[0m: You must run the sampler with 'store == True' before accessing the results"
     ]
    }
   ],
   "source": [
    "filename = \"../../../COVID19_Disparities/COVID19_Disparities/calib_Disparities_small-20241004_backend.h5\"\n",
    "sampler = emcee.backends.HDFBackend(filename, read_only=True)\n",
    "\n",
    "\n",
    "chain_index = -1 # -1 for last\n",
    "\n",
    "# This selects the n_samples slots/walkers with the highest likelihood, and take their last evaluation. \n",
    "# Debatable, but it's a start.\n",
    "max_indices = np.argsort(sampler.get_log_prob()[chain_index, :])[-nsamples:]\n",
    "print(sampler.get_chain().shape)\n",
    "chains = sampler.get_chain()[:chain_index, max_indices, :]        # the last iteration, for selected slots\n",
    "samples = sampler.get_chain()[chain_index, max_indices, :]  # the last iteration, for selected slots\n",
    "llik = sampler.get_log_prob()[:chain_index, max_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a305d85",
   "metadata": {},
   "source": [
    "## 3. plot the chains\n",
    "this saves a .pdf files. Only plot the n_samples from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc74aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gempyor.postprocess_inference.plot_chains(\n",
    "        inferpar=gempyor_inference.inferpar, chains=chains, llik=llik, sampled_slots=None, save_to=f\"{run_id}_chains2.pdf\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb10b563",
   "metadata": {},
   "source": [
    "## 4. Generate `n_samples` simulations\n",
    "\n",
    "**THIS REMOVES MODEL_OUTPUT**\n",
    "\n",
    "In case your cluster run did not finish, this takes the values of parameter selected with n_samples and put them in gempyor to get the simulation. Can be long if n_samples is big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8065f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the simulations\n",
    "shutil.rmtree(\"model_output/\", ignore_errors=True)\n",
    "shutil.rmtree(os.path.join(project_path, \"model_output/\"), ignore_errors=True)\n",
    "gempyor_inference.set_save(True)\n",
    "with multiprocessing.Pool(ncpu) as pool:\n",
    "    results = pool.starmap(\n",
    "        gempyor_inference.get_logloss_as_single_number, [(samples[i, :],) for i in range(len(max_indices))]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bcf77de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# read the hosp files\n",
    "results = []\n",
    "for fn in gempyor.utils.list_filenames(folder=project_path+\"/model_output/\", filters=[\"hosp.parquet\"]): ## TODO: here project path is correct, but use to concatenate path. the right way\n",
    "   df = gempyor.read_df(fn)\n",
    "   df = df.set_index(\"date\")\n",
    "   results.append(df)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2556738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the simulations with and without projections\n",
    "gempyor.postprocess_inference.plot_fit(modinf=gempyor_inference.modinf, loss=gempyor_inference.logloss, list_of_df=results, save_to=f\"{run_id}_fit_gtdates.pdf\")\n",
    "gempyor.postprocess_inference.plot_fit(modinf=gempyor_inference.modinf, loss=gempyor_inference.logloss,plot_projections=True, list_of_df=results, save_to=f\"{run_id}_fit_proj.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
